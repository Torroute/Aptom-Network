import re
import random
import requests
from bs4 import BeautifulSoup
from duckduckgo_search import ddg_answers

# List of 110 known dark web index URLs (can be expanded or updated as needed)
hidden_wiki_urls = [
    'http://wikitjerrta4qhzl.onion',
    'http://thehiddenwiki.org.onion',
    'http://zlal32teyptf4k2y.onion',
    'http://vvo4cpohruwmzd62.onion',
    'http://darkweb.link.onion',
    'http://freshonions4all.onion',
    'http://hiddendirectory4.onion',
    'http://darkwebdirectory.onion',
    'http://gimmebacon.onion',
    'http://grn5qhtsfg4j6fkg.onion',
    'http://guf3nbhhd47s66rc.onion',
    'http://site4onion.onion',
    'http://pythonscript.onion',
    'http://hydra-market.onion',
    'http://themarketplace.onion',
    'http://blockchainmarket.onion',
    'http://anonbin.onion',
    'http://freedomhosting2.onion',
    'http://reddit-darkweb.onion',
    'http://beary.onion',
    'http://oniondirctory.onion',
    'http://darkwebforreal.onion',
    'http://newhiddenwiki.onion',
    'http://hiddenwikiindex.onion',
    'http://darkwebspecial.onion',
    'http://oniontree.onion',
    'http://thehiddenweb.onion',
    'http://cyberstealth.onion',
    'http://topdarkwebsites.onion',
    'http://deepweblinks.onion',
    'http://bestdarkweb.onion',
    'http://deepwebindex.onion',
    'http://securitywiki.onion',
    'http://privatebrowsing.onion',
    'http://onionfinder.onion',
    'http://darknetmarketplace.onion',
    'http://torlinks.onion',
    'http://dwmatrix.onion',
    'http://onionlist.onion',
    'http://darkwebarchive.onion',
    'http://oniondirect.onion',
    'http://onionlinks.org.onion',
    'http://darknettools.onion',
    'http://hiddenservicesdirectory.onion',
    'http://onionnetworks.onion',
    'http://toronionlist.onion',
    'http://topdarkwebsites2.onion',
    'http://torhiddenwiki.onion',
    'http://darknetindex.onion',
    'http://deepweb1.onion',
    'http://darkwebsitesindex.onion',
    'http://hiddenwiki2018.onion',
    'http://newdarkwebdirectory.onion',
    'http://hiddenonionlist.onion',
    'http://darkwebdir.onion',
    'http://theonionindex.onion',
    'http://onionpages.onion',
    'http://exploreonion.onion',
    'http://darkwebpost.onion',
    'http://onionworld.onion',
    'http://oniondirs.onion',
    'http://onionaggregator.onion',
    'http://hiddenwiki2.onion',
    'http://freedomdirectory.onion',
    'http://onionmap.onion',
    'http://oniontourism.onion',
    'http://darkweblinks.onion',
    'http://anonymized.onion',
    'http://secureonions.onion',
    'http://theonionsearch.onion',
    'http://onionreality.onion',
    'http://darknetgo.onion',
    'http://onionbrowser.onion',
    'http://deepweblookup.onion',
    'http://oniondb.onion',
    'http://darkwebonline.onion',
    'http://deepwebexplorer.onion',
    'http://secureonionlist.onion',
    'http://deepdarkweb.onion',
    'http://hiddenpath.onion',
    'http://onionmapdirectory.onion',
    'http://darkwebdirectory2.onion',
    'http://hiddenonionexplorer.onion',
    'http://onionarchives.onion',
    'http://onionbase.onion',
    'http://searchdarkweb.onion',
    'http://hiddenlinks.onion',
    'http://onionbase2.onion',
    'http://exploreonion2.onion',
    'http://darkwebfinder.onion',
    'http://stealthhiddenwiki.onion',
    'http://onionexplorer.onion',
    'http://darknetindexes.onion',
    'http://onionsearcher.onion',
    'http://oniontools.onion',
    'http://anonlist.onion',
    'http://darkwebindex2.onion',
    'http://searchoniondir.onion',
    'http://secretonionlinks.onion',
    'http://onionlistindex.onion',
    'http://newoniondirectory.onion',
    'http://hiddenserviceindex.onion'
]

def scan_duckduckgo_onions(query, num_pages=3, output_file='onion_domains.txt'):
    """
    Scans multiple DuckDuckGo pages for .onion domains and writes the results to a file.
    
    Args:
        query (str): The search query to input to DuckDuckGo.
        num_pages (int): The number of search result pages to scan.
        output_file (str): The name of the file to write the .onion domains to.
    
    Returns:
        None
    """
    onion_domains = set()
    
    def extract_onion_domains(url):
        # Regular expression to match .onion domains
        onion_pattern = r'\b[A-Za-z2-7]{16}\.onion\b'
        return re.findall(onion_pattern, url)
    
    # Scrape DuckDuckGo search results for .onion domains
    for page_num in range(1, num_pages + 1):
        search_results = ddg_answers(query, max_results=50, page=page_num)
        for result in search_results:
            if 'url' in result:
                onion_domains.update(extract_onion_domains(result['url']))
    
    # Scrape a few known dark web index pages
    for hidden_wiki_url in random.sample(hidden_wiki_urls, min(5, len(hidden_wiki_urls))):
        print(f"Scraping {hidden_wiki_url}...")
        try:
            response = requests.get(hidden_wiki_url, timeout=10)
            if
